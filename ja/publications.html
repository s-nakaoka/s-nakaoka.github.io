<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta content="text/html; charset=UTF-8" http-equiv="content-type">
  <title>中岡 慎一郎　発表文献（日本語）</title>
</head>
<body>

<div style="text-align: right;"><a href="../index.html#publications">発表文献(英語)</a></div>

<h2>発表文献(日本語)</h2>

<h3>学術論文(査読有り)</h3>
<ul>
<li>
<u>中岡慎一郎</u>, 三浦郁奈子, 森澤光晴, 金広文男, 金子健二, 梶田秀司, 横井一仁,
「ヒューマノイドロボットのコンテンツ技術化に向けて - クリエイターによる多様な表現の創出が可能な二足歩行ヒューマノイドロボットの実現 -」,
シンセシオロジー, Vol.4, No.2, pp.80-91, 2011年5月
(<a href="http://www.aist.go.jp/synthesiology/vol04_02/vol04_02_p80_p91.pdf">PDF</a>).
</li>
<br/>
<li>
三浦郁奈子, <u>中岡慎一郎</u>, 金広文男, 原田研介, 金子健二, 横井一仁, 梶田秀司,
「足裏の滑りを利用した2足歩行ロボットの方向転換 -滑り現象のモデル化と回転角の予測-」,
日本ロボット学会誌, Vol. 28, No. 10, pp. 84-94, 2010年.
</li>
<br/>
<li>
金子健二, 金広文男, 森澤光晴, 三浦郁奈子, 中岡慎一郎, 原田研介, 梶田秀司,
「サイバネティックヒューマンHRP-4Cの開発　-プロジェクト概要からシステム設計まで-」,
日本ロボット学会誌, Vol. 28, No. 7, pp. 79-90, 2010年.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 中澤篤志, 金広文男, 金子健二, 森澤光晴, 比留川博久, 池内克史,
「脚タスクモデルを用いた２足歩行ヒューマノイドロボットによる人の舞踊動作の再現」, 日本ロボット学会誌, Vol. 24, No. 3, 
pp.112–123, 2006年.
</li>
<br/>
</ul>

<h3>解説記事</h3>
<ul>
<li>
<u>中岡 慎一郎</u>,
「拡張可能なロボット用統合GUI環境Choreonoid」,
日本ロボット学会誌, Vol. 31, No. 3, pp. 12-17, 2013年.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 山野辺夏樹, 比留川博久, 山根克, 川角祐一郎,
「分散コンポーネント型ロボットシミュレータOpenHRP3」,
日本ロボット学会誌, Vol. 26, No. 5, pp. 399-406, 2008年.
</li>
<br/>
<li>
安藤慶昭, <u>中岡慎一郎</u>, 神徳徹雄,
「分散コンポーネント型ロボットシミュレータ・アーキテクチャ - {R}{T}コンポーネントを用いた実機と可換な制御ソフトウェア開発機能 -」,
日本ロボット学会誌, Vol. 26, No. 5, pp. 407--414, 2008年.
</li>
<br/>
<li>
池内克史, 中澤篤志, 小川原光一, 高松淳, 工藤俊輔, <u>中岡慎一郎</u>, 白鳥貴亮,
「民族芸能のデジタルアーカイブとロボットによる動作提示」, 日本バーチャルリアリティ学会学会誌,
Vol. 9, No. 2, pp. 14–20, 2004年.
</li>
<br/>
</ul>

<h3>国内会議（査読有り）</h3>
<ul>
<li>
<u>中岡慎一郎</u>, 中澤篤志, 金広文男, 金子健二, 森澤光晴, 池内克史, 「下半身タスクモデルを用いた舞踊動作の認識と生成」,
情報処理学会MIRU2005 論文集, pp. 447–454, 淡路島, 7 2005. <u>インタラクティブセッション賞受賞</u>
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 中澤篤志, 横井一仁, 池内克史, 「人の全身動作をロボットで模倣するための動作プリミティブ」,
画像の認識・理解シンポジウムMIRU2004 講演予稿集, 函館, 7 2004.
</li>
<br/>
<li>
中澤篤志, <u>中岡慎一郎</u>, 竹村治雄, 池内克史, 「スケーラブルDP を用いた人間動作のマッチングと生成」,
画像の認識・理解シンポジウムMIRU2004 講演予稿集, 第I 巻, pp. 171–176, 函館, 4月 2004.
</li>
<br/>
<li>
中澤篤志, <u>中岡慎一郎</u>, 工藤俊亮, 池内克史, 「視覚による舞踊動作の保存・解析および生成」, 画像の認識・理解シンポジウム, 
第I 巻, pp.153–158, 2002.
</li>
<br/>
</ul>

<h3>国内会議（査読無し）</h3>

<ul>
<li>
<u>中岡慎一郎</u>, 幸村琢,
「インタラクションメッシュを用いたヒューマノイドロボットへの動作リターゲティング」,
第31回日本ロボット学会学術講演会, 東京, 2013年9月, pp. 1C1-07 (<a href="1C1-07.pdf">PDF</a>).
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 梶田秀司, 三浦郁奈子, 森澤光晴, 横井一仁,
「ロボット動作振り付けソフトウェアChoreonoidによるコンテンツ制作実験」,
第29回日本ロボット学会学術講演会, pp. 1J3-1, 2011年9月.
</li>
<br/>
<li>
金子健二, 金広文男, 森澤光晴, 三浦郁奈子, <u>中岡慎一郎</u>, 梶田秀司, 横井 一仁,
「エンターテインメント応用に向けたサイバネティックヒューマンHRP-4Cの改良」,
第28回日本ロボット学会学術講演会, pp. 1A3-4, 2010年.
</li>
<br/>
<li>
梶田秀司, 森澤光晴, 三浦郁奈子, <u>中岡慎一郎</u>, 金子健二, 金広文男, 横井一仁,
「線形倒立振子トラッキング制御による不整地２足歩行制御」,
第28回日本ロボット学会学術講演会, pp. 2D2-8, 2010年.
</li>
<br/>
<li>
橘誠, <u>中岡慎一郎</u>, 剣持秀紀,
「歌うロボット -VOCALOIDとサイバネティックヒューマンHRP-4Cのコラボレーション-」,
情報処理学会研究報告, Vol. 2010-MUS-84, No. 14, 2010年.
</li>
<br/>
<li>
梶田秀司, 金子健二, 金広文男, 原田研介, 森澤光晴, <u>中岡慎一郎</u>, 三浦郁奈子, 藤原清司, Neo Ee Sien, 原功, 横井一仁, 比留川博久,
「サイバネティックヒューマンHRP-4Cの開発 - プロジェクト概要 -」,
第27回日本ロボット学会学術講演会, 2009年.
</li>
<br/>
<li>
金子健二, 金広文男, 森澤光晴, 三浦郁奈子, <u>中岡慎一郎</u>, 梶田秀司,
「サイバネティックヒューマンHRP-4Cの開発 - システム設計 -」,
第27回日本ロボット学会学術講演会, 2009年.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 比留川 博久,
「OpenRT Platform / 動作パターン設計ツール」,
ロボティクス・メカトロニクス講演会 ROBOMEC2009,
福岡, pp. 2A2-C12, 2009年5月.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 池内克史,
「脚動作の認識に基づく舞踊動作観察学習ロボットの実現」,
情報処理学会研究報告　コンピュータビジョンとイメージメディア, Vol. 2006, No. 51, pp. 323–338, 2006年5月.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 中澤篤志, 横井一仁, 池内克史,
「シンボリックな動作記述を用いた舞踊動作摸倣ロボットの実現」,
電子情報通信学会技術研究報告　パターン認識・メディア理解, Vol. 103, No.390, pp. 55–60, 2003年10月.
</li>
<br/>
<li>
<u>中岡慎一郎</u>, 中澤篤志, 横井一仁, 池内克史,
「舞踊動作を模倣するロボットの全身動作の生成」,
SCIE SI2002 講演論文集（I）, pp. 293–294. 計測自動制御学会, 2002年12月. <u>ベストセッション賞受賞</u>.
</li>
<br/>
<li>
中澤篤志, <u>中岡慎一郎</u>, 池内克史,
「モーションキャプチャデータからの舞踊動作プリミティブの抽出」,
第19回日本ロボット学会学術講演会, pp. 907–908, 東京, 2001年9月.
</li>
</ul>

</body>
</html>
